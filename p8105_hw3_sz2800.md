p8105\_hw3\_sz2800.Rmd
================
Stephanie Zhen
10/14/2019

``` r
library (tidyverse)
```

    ## -- Attaching packages ----------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.2.1     v purrr   0.3.2
    ## v tibble  2.1.3     v dplyr   0.8.3
    ## v tidyr   1.0.0     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.4.0

    ## -- Conflicts -------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library (viridis)
```

    ## Loading required package: viridisLite

``` r
library (p8105.datasets)
```

## Q1: Instacart

``` r
data("instacart")
```

The dimension of instacart is 1384617, 15 with 1384617 observations and
the following key variables: order\_id, product\_id,
add\_to\_cart\_order, reordered, user\_id, eval\_set, order\_number,
order\_dow, order\_hour\_of\_day, days\_since\_prior\_order,
product\_name, aisle\_id, department\_id, aisle, department.

``` r
count = instacart %>%
  group_by(aisle)%>% 
  summarize(aisle_count = n()) %>% 
  arrange(desc(aisle_count))
```

Based on the instacart data, there are 134 types of aisles with fresh
vegetables being the most popular aisles with 150609 aisles.

Plot with number of items ordered in each aisle, limiting to aisles with
more than 10000 items ordered.

``` r
items_aisles = count %>% 
  filter(aisle_count > 10000)

items_aisles_plot = ggplot(data = items_aisles, aes(x = reorder(aisle, aisle_count), y = aisle_count)) +
  geom_bar(stat = "identity") + 
  labs(x = "Aisle", y = "Number of Times", title = "Distribution of Aisle") +
  coord_flip() 
```

There is 39 aisles that has more than 10000 items ordered with the least
amount of orders from butter with 10575 orders and the largest number of
orders from fresh vegetables, a total of 150609 orders.

Table with the three most popular items in each of the aisles “baking
ingredients”, “dog food care”, and “packaged vegetables fruits”.

``` r
aisles_tables = instacart %>% 
  select(aisle, product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(pop_count = n()) %>% 
  top_n(3)
```

    ## Selecting by pop_count

Table with mean hour of the day at which Pink Lady Apples and Coffee Ice
Cream are ordered on each day of the week.

``` r
sweets = instacart %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by (product_name, order_dow) %>% 
  summarize(mean_time = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_time
  ) 

knitr::kable(sweets, digits = 2)
```

| product\_name      |        0 |        1 |       2 |        3 |       4 |        5 |             6 |
| :----------------- | -------: | -------: | ------: | -------: | ------: | -------: | ------------: |
| Coffee Ice Cream   |    13.77 |    14.32 |   15.38 |    15.32 |   15.22 |    12.26 |         13.83 |
| Pink Lady Apples   |    13.44 |    11.36 |   11.70 |    14.25 |   11.55 |    12.78 |         11.94 |
| Assumed, Sunday is | equivale | nt to ze | ro, and | Monday - | Saturda | y follws | sequentially. |

## Q2 BRFSS

Data cleaning:“Overall Health” topic with ordered responses from
“Excellent” to “Poor”.

``` r
data(brfss_smart2010)

brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
  mutate(response = as.factor(response)) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  arrange(response)
```

In 2002, which states were observed at 7 or more locations? What about
in 2010?

``` r
state_loca_02 = brfss %>% 
  filter (year == 2002) %>% 
  group_by (locationabbr) %>% 
  summarize(distinct_loca = n_distinct(locationdesc)) %>%
  filter (distinct_loca >= 7) 

state_loca_10 = brfss %>% 
  filter (year == 2010) %>% 
  group_by (locationabbr) %>% 
  summarize(distinct_loca = n_distinct(locationdesc)) %>%
  filter (distinct_loca >= 7) 
```

The states that were observed at 7 or more locations are: CT, FL, MA,
NC, NJ, PA. The states that are observed at 7 or more locations at 2010
are: CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA.

Make a “spaghetti” plot of average data\_value over time within a state
limited to only “Excellent” responses.

``` r
brfss_preplot = brfss %>% 
  select(year, response, locationabbr, data_value) %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data = mean(data_value, na.rm = TRUE))

brfss_plot = ggplot(data = brfss_preplot, aes(x = year, y = mean_data, color = locationabbr)) + 
    geom_line() +
  labs(title = "Average Data value Over Time within a State", x = "Years", y = "Average Data", color = "States")
```

Make a two-panel plot showing, for the years 2006, and 2010,
distribution of data\_value for responses (“Poor” to “Excellent”) among
locations in NY State.

``` r
brfss_ny = brfss %>% 
  select(year, data_value, response, locationdesc, locationabbr) %>% 
  filter(year == c(2006, 2010), locationabbr == "NY")
```

    ## Warning in year == c(2006, 2010): longer object length is not a multiple of
    ## shorter object length

``` r
brfss_ny_plot = ggplot(data = brfss_ny, aes(x = response, y = data_value)) +
  geom_boxplot() +
  facet_wrap(~year) + 
  labs(title = "Average Data value for Responses in NY", x = "Response", y = "Average Data")
```

## Q3: Accelerometers

Tidying Accel Dataset.

``` r
accel = read_csv("./accel_data.csv") %>%
  janitor::clean_names() %>% 
  mutate(day_week = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "time_mins",
    names_prefix = "activity_",
    values_to = "activity"
  ) %>%
  mutate(time_mins = as.numeric(time_mins))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

Aggregate accross minutes to create a total activity variable for each
day.

``` r
accel_sum_table = accel %>% 
  group_by(day, day_id) %>% 
  summarize(total_act = sum(activity), avg_act = mean(activity))

accel_sum_plot_1 = ggplot(accel_sum_table, aes(x = day_id, y = total_act)) +
  geom_line()

knitr::kable(accel_sum_table, digits = 2)
```

| day       | day\_id | total\_act | avg\_act |
| :-------- | ------: | ---------: | -------: |
| Friday    |       1 |  480542.62 |   333.71 |
| Friday    |       8 |  568839.00 |   395.03 |
| Friday    |      15 |  467420.00 |   324.60 |
| Friday    |      22 |  154049.00 |   106.98 |
| Friday    |      29 |  620860.00 |   431.15 |
| Monday    |       2 |   78828.07 |    54.74 |
| Monday    |       9 |  295431.00 |   205.16 |
| Monday    |      16 |  685910.00 |   476.33 |
| Monday    |      23 |  409450.00 |   284.34 |
| Monday    |      30 |  389080.00 |   270.19 |
| Saturday  |       3 |  376254.00 |   261.29 |
| Saturday  |      10 |  607175.00 |   421.65 |
| Saturday  |      17 |  382928.00 |   265.92 |
| Saturday  |      24 |    1440.00 |     1.00 |
| Saturday  |      31 |    1440.00 |     1.00 |
| Sunday    |       4 |  631105.00 |   438.27 |
| Sunday    |      11 |  422018.00 |   293.07 |
| Sunday    |      18 |  467052.00 |   324.34 |
| Sunday    |      25 |  260617.00 |   180.98 |
| Sunday    |      32 |  138421.00 |    96.13 |
| Thursday  |       5 |  355923.64 |   247.17 |
| Thursday  |      12 |  474048.00 |   329.20 |
| Thursday  |      19 |  371230.00 |   257.80 |
| Thursday  |      26 |  340291.00 |   236.31 |
| Thursday  |      33 |  549658.00 |   381.71 |
| Tuesday   |       6 |  307094.24 |   213.26 |
| Tuesday   |      13 |  423245.00 |   293.92 |
| Tuesday   |      20 |  381507.00 |   264.94 |
| Tuesday   |      27 |  319568.00 |   221.92 |
| Tuesday   |      34 |  367824.00 |   255.43 |
| Wednesday |       7 |  340115.01 |   236.19 |
| Wednesday |      14 |  440962.00 |   306.22 |
| Wednesday |      21 |  468869.00 |   325.60 |
| Wednesday |      28 |  434460.00 |   301.71 |
| Wednesday |      35 |  445366.00 |   309.28 |

There is no trend between total activity and days. There is no uniform
decrease or uniform increase in the activities as the days passes.

Plot of daily activities across days of the
week.

``` r
accel_sum_plot_2 = ggplot(accel_sum_table, aes(x = day_id, y = total_act, color = day)) +
  geom_smooth() +
  labs(x = "Day", y = "Total Activity", title = "Daily Activity across 35 Days", color = "Day of the Week")
```

There is no general trend in the activity as the days increase, and
there is no uniform increase of decrease in activity between the
different days of the week.
