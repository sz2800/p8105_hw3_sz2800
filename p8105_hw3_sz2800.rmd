---
title: "p8105_hw3_sz2800.Rmd"
author: "Stephanie Zhen"
date: "10/14/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library (tidyverse)
library (viridis)
library (p8105.datasets)
```

## Q1: Instacart
```{r}
data("instacart")
```

Instacart is an online grocery service that allows people to shop online from local stores. The dimension of instacart dataset is `r dim(instacart)` with `r nrow(instacart)` observations and the following key variables: `r colnames(instacart)`. The fifth order of the dataset is "Lightly Smoked Sardines in Olive Oil", in the aisle: Canned Meat and Seafoods.

```{r}
count = instacart %>%
  group_by(aisle)%>% 
  summarize(aisle_count = n()) %>% 
  arrange(desc(aisle_count))
```
Based on the instacart data, there are `r nrow(count)` types of aisles with `r first(pull(count, aisle))` being the most popular aisles with `r max(pull(count, aisle_count))` aisles. 

Plot with number of items ordered in each aisle, limiting to aisles with more than 10000 items ordered.
```{r}
items_aisles = count %>% 
  filter(aisle_count > 10000)

items_aisles_plot = ggplot(data = items_aisles, aes(x = reorder(aisle, aisle_count), y = aisle_count)) +
  geom_bar(stat = "identity") + 
  labs(x = "Aisle", y = "Number of Times", title = "Distribution of Aisle") +
  coord_flip() 
```
There is `r nrow(items_aisles)` aisles that has more than 10000 items ordered with the least amount of orders from `r last(pull(items_aisles, aisle))` with `r min(pull(items_aisles, aisle_count))` orders and the largest number of orders from `r first(pull(items_aisles, aisle))`, a total of `r max(pull(items_aisles, aisle_count))` orders.

Table with the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
```{r}
aisles_tables = instacart %>% 
  select(aisle, product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(pop_count = n()) %>% 
  top_n(3)

knitr::kable(aisles_tables,
             format = "html",
             digits = 0,
             caption = "Three most popular items from baking ingredients, dog food care, packaged vegetables fruits")
```

Table with mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.
```{r}
sweets = instacart %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by (product_name, order_dow) %>% 
  summarize(mean_time = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_time
  ) 

knitr::kable(sweets, 
             format = "html",
             digits = 2,
             caption = "Average order time for Pink Lady Apples and Coffee Ice Cream")
```
Assumed, Sunday is equivalent to zero, and Monday - Saturday follows sequentially.

## Q2 BRFSS
Data cleaning:“Overall Health” topic with ordered responses from “Excellent” to “Poor”.
```{r}
data(brfss_smart2010)

brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
  mutate(response = as.factor(response)) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  arrange(response)
```

In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
state_loca_02 = brfss %>% 
  filter (year == 2002) %>% 
  group_by (locationabbr) %>% 
  summarize(distinct_loca = n_distinct(locationdesc)) %>%
  filter (distinct_loca >= 7) 
knitr::kable(state_loca_02, 
             format = "html",
             digits = 0,
             caption = "States Observed at 7 more locations in 2002")

state_loca_10 = brfss %>% 
  filter (year == 2010) %>% 
  group_by (locationabbr) %>% 
  summarize(distinct_loca = n_distinct(locationdesc)) %>%
  filter (distinct_loca >= 7) 
knitr::kable(state_loca_10, 
             format = "html",
             digits = 0,
             caption = "States Observed at 7 more locations in 2010")
```

The states that were observed at 7 or more locations are: `r pull(state_loca_02,locationabbr)`. The states that are observed at 7 or more locations at 2010 are:  `r pull(state_loca_10,locationabbr)`.

Make a “spaghetti” plot of average data_value over time within a state limited to only "Excellent" responses.
```{r}
brfss_preplot = brfss %>% 
  select(year, response, locationabbr, data_value) %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data = mean(data_value, na.rm = TRUE))

brfss_plot = ggplot(data = brfss_preplot, aes(x = year, y = mean_data, color = locationabbr)) + 
    geom_line() +
  labs(title = "Average Data value Over Time within a State", x = "Years", y = "Average Data", color = "States")
```

A two-panel plot for the years 2006, and 2010, showing distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r}
brfss_ny = brfss %>% 
  select(year, data_value, response, locationdesc, locationabbr) %>% 
  filter(year == c(2006, 2010), locationabbr == "NY")
  
brfss_ny_plot = ggplot(data = brfss_ny, aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  facet_wrap(~year) + 
  labs(title = "Average Data value for Responses in NY", x = "Response", y = "Average Data", color = "Response")
```

## Q3: Accelerometers 

Tidying Accel Dataset.
```{r}
accel = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "time_mins",
    names_prefix = "activity_",
    values_to = "activity"
  ) %>%
  mutate(time_hour = ceiling(as.numeric(time_mins)/60)) %>% 
  mutate(day_week = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")) %>% 
  mutate(day = as.factor(day), 
         day = forcats::fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))
```

In the accel dataset, the key variables are: `r colnames(accel)` with `r nrow(accel)` observations. Each observation is the activity per minute over the course of 5 weeks, of a 63 year old male, with BMI 25, diagnosed with congested heart failure. 

Aggregate accross minutes to create a total activity variable for each day. 
```{r}
accel_sum_table = accel %>% 
  group_by(day, day_id) %>% 
  summarize(total_act = sum(activity), avg_act = mean(activity))

accel_sum_plot_1 = ggplot(accel_sum_table, aes(x = day_id, y = total_act)) +
  geom_line()

knitr::kable(accel_sum_table, 
            format = "html",
             digits = 2)
```

There is no trend between total activity and days. There is no uniform decrease or uniform increase in the activities as the days passes. 

Plot of daily activities across days of the week. 
```{r}
accel_sum_hour = accel %>% 
  group_by(day, time_hour) %>% 
  summarize(total_act = sum(activity, na.rm = TRUE), avg_act = mean(activity,  na.rm = TRUE))

accel_sum_plot_2 = ggplot(accel_sum_hour, aes(x = time_hour, y = total_act, color = day)) +
  geom_smooth() +
  labs(x = "Time (Hours)", y = "Total Activity", title = "Daily Activity across Days of the Weeks", color = "Day of the Week") +
  xlim(1, 24)
```

Based on the graph, it looks like Sunday shows the largest differences in activity. In general, activity increase from 1-10 hours then plateaus and decreases by the 20th hour. 
