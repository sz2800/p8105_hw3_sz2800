---
title: "p8105_hw3_sz2800.Rmd"
author: "Stephanie Zhen"
date: "10/14/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library (tidyverse)
library (viridis)
library (p8105.datasets)
```

## Q1: Instacart
```{r}
data("instacart")
```

The dimension of instacart is `r dim(instacart)` with `r nrow(instacart)` observations and the following key variables: `r colnames(instacart)`.

```{r}
count = instacart %>%
  group_by(aisle)%>% 
  summarize(aisle_count = n()) %>% 
  arrange(desc(aisle_count))
```
Based on the instacart data, there are `r nrow(count)` types of aisles with `r first(pull(count, aisle))` being the most popular aisles with `r max(pull(count, aisle_count))` aisles. 

Plot with number of items ordered in each aisle, limiting to aisles with more than 10000 items ordered.
```{r}
items_aisles = count %>% 
  filter(aisle_count > 10000)

items_aisles_plot = ggplot(data = items_aisles, aes(x = reorder(aisle, aisle_count), y = aisle_count)) +
  geom_bar(stat = "identity") + 
  labs(x = "Aisle", y = "Number of Times", title = "Distribution of Aisle") +
  coord_flip() 
```
There is `r nrow(items_aisles)` aisles that has more than 10000 items ordered with the least amount of orders from `r last(pull(items_aisles, aisle))` with `r min(pull(items_aisles, aisle_count))` orders and the largest number of orders from `r first(pull(items_aisles, aisle))`, a total of `r max(pull(items_aisles, aisle_count))` orders.

Table with the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
```{r}
aisles_tables = instacart %>% 
  select(aisle, product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(pop_count = n()) %>% 
  top_n(3)
```

Table with mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.
```{r}
sweets = instacart %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by (product_name, order_dow) %>% 
  summarize(mean_time = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_time
  ) 

knitr::kable(sweets, digits = 2)
```
Assumed, Sunday is equivalent to zero, and Monday - Saturday follws sequentially.

## Q2 BRFSS
Data cleaning:“Overall Health” topic with ordered responses from “Excellent” to “Poor”.
```{r}
data(brfss_smart2010)

brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
  mutate(response = as.factor(response)) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  arrange(response)
```

In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
state_loca_02 = brfss %>% 
  filter (year == 2002) %>% 
  group_by (locationabbr) %>% 
  summarize(distinct_loca = n_distinct(locationdesc)) %>%
  filter (distinct_loca >= 7) 

state_loca_10 = brfss %>% 
  filter (year == 2010) %>% 
  group_by (locationabbr) %>% 
  summarize(distinct_loca = n_distinct(locationdesc)) %>%
  filter (distinct_loca >= 7) 
```
The states that were observed at 7 or more locations are: `r pull(state_loca_02,locationabbr)`. The states that are observed at 7 or more locations at 2010 are:  `r pull(state_loca_10,locationabbr)`.

Make a “spaghetti” plot of average data_value over time within a state limited to only "Excellent" responses.
```{r}
brfss_preplot = brfss %>% 
  select(year, response, locationabbr, data_value) %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data = mean(data_value, na.rm = TRUE))

brfss_plot = ggplot(data = brfss_preplot, aes(x = year, y = mean_data, color = locationabbr)) + 
    geom_line() +
  labs(title = "Average Data value Over Time within a State", x = "Years", y = "Average Data", color = "States")
```

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r}
brfss_ny = brfss %>% 
  select(year, data_value, response, locationdesc, locationabbr) %>% 
  filter(year == c(2006, 2010), locationabbr == "NY")
  
brfss_ny_plot = ggplot(data = brfss_ny, aes(x = response, y = data_value)) +
  geom_boxplot() +
  facet_wrap(~year) + 
  labs(title = "Average Data value for Responses in NY", x = "Response", y = "Average Data")
```

## Q3: Accelerometers 

Tidying Accel Dataset.
```{r}
accel = read_csv("./accel_data.csv") %>%
  janitor::clean_names() %>% 
  mutate(day_week = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "time_mins",
    names_prefix = "activity_",
    values_to = "activity"
  ) %>%
  mutate(time_mins = as.numeric(time_mins))
```

Aggregate accross minutes to create a total activity variable for each day. 
```{r}
accel_sum_table = accel %>% 
  group_by(day, day_id) %>% 
  summarize(total_act = sum(activity), avg_act = mean(activity))

accel_sum_plot_1 = ggplot(accel_sum_table, aes(x = day_id, y = total_act)) +
  geom_line()

knitr::kable(accel_sum_table, digits = 2)
```

There is no trend between total activity and days. There is no uniform decrease or uniform increase in the activities as the days passes. 

Plot of daily activities across days of the week. 
```{r}
accel_sum_plot_2 = ggplot(accel_sum_table, aes(x = day_id, y = total_act, color = day)) +
  geom_smooth() +
  labs(x = "Day", y = "Total Activity", title = "Daily Activity across 35 Days", color = "Day of the Week")
```

There is no general trend in the activity as the days increase, and there is no uniform increase of decrease in activity between the different days of the week. 
